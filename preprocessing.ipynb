{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "# 1. to handle the data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2. To Viusalize the data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# 3. To preprocess the data\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "# 4. import Iterative imputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# 5. Machine Learning\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV, cross_val_score\n",
        "\n",
        "# 6. For Classification task.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier,RandomForestRegressor\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "# 7. Metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 8. Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "# improt ALl models.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#importing pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, r2_score\n"
      ],
      "metadata": {
        "id": "_SIZONbhFLvo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LYKmDJdwOam4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j8Hv8vXNOajZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data():\n",
        "  train_df = pd.read_csv('train_data_with_ids.csv')\n",
        "  test_df = pd.read_csv('test_data_with_ids.csv')\n",
        "  return train_df, test_df\n"
      ],
      "metadata": {
        "id": "DS0Egd82Gg8J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop(df):\n",
        "  return df.dropna()"
      ],
      "metadata": {
        "id": "DbZwrBdrFnnL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imputeMean(df):\n",
        "    ordinal_cols = ['slope', 'thal']\n",
        "    nominal_cols = ['cp', 'restecg', 'sex']\n",
        "    numerical_cols = ['oldpeak', 'thalch', 'chol', 'trestbps', 'age','ca']\n",
        "    bool_cols = ['fbs', 'exang']\n",
        "\n",
        "    # Fill numerical NAs with the column's mean value\n",
        "    for col in numerical_cols:\n",
        "        df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "    # Fill categorical NAs with the most frequent value (mode)\n",
        "    for col in ordinal_cols + nominal_cols + bool_cols:\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "x1fWR0CiQ7Q_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imputeML(df):\n",
        "    missing_data_cols = df.isnull().sum()[df.isnull().sum()>0].index.tolist()\n",
        "    categorical_cols = ['thal', 'ca', 'slope', 'exang', 'restecg','fbs', 'cp', 'sex', 'num']\n",
        "    bool_cols = ['fbs', 'exang']\n",
        "    numerical_cols = ['oldpeak', 'thalch', 'chol', 'trestbps', 'age']\n",
        "    passed_col = categorical_cols\n",
        "    def impute_categorical_missing_data(passed_col):\n",
        "\n",
        "        df_null = df[df[passed_col].isnull()]\n",
        "        df_not_null = df[df[passed_col].notnull()]\n",
        "\n",
        "        X = df_not_null.drop(passed_col, axis=1)\n",
        "        y = df_not_null[passed_col]\n",
        "\n",
        "        other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        for col in X.columns:\n",
        "            if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
        "                X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "        if passed_col in bool_cols:\n",
        "            y = label_encoder.fit_transform(y)\n",
        "\n",
        "        iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)\n",
        "\n",
        "        for col in other_missing_cols:\n",
        "            if X[col].isnull().sum() > 0:\n",
        "                col_with_missing_values = X[col].values.reshape(-1, 1)\n",
        "                imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
        "                X[col] = imputed_values[:, 0]\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        rf_classifier = RandomForestClassifier()\n",
        "\n",
        "        rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "        acc_score = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        print(\"The feature '\"+ passed_col+ \"' has been imputed with\", round((acc_score * 100), 2), \"accuracy\\n\")\n",
        "\n",
        "        X = df_null.drop(passed_col, axis=1)\n",
        "\n",
        "        for col in X.columns:\n",
        "            if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
        "                X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "        for col in other_missing_cols:\n",
        "            if X[col].isnull().sum() > 0:\n",
        "                col_with_missing_values = X[col].values.reshape(-1, 1)\n",
        "                imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
        "                X[col] = imputed_values[:, 0]\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        if len(df_null) > 0:\n",
        "            df_null[passed_col] = rf_classifier.predict(X)\n",
        "            if passed_col in bool_cols:\n",
        "                df_null[passed_col] = df_null[passed_col].map({0: False, 1: True})\n",
        "            else:\n",
        "                pass\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        df_combined = pd.concat([df_not_null, df_null])\n",
        "\n",
        "        return df_combined[passed_col]\n",
        "\n",
        "    def impute_continuous_missing_data(passed_col):\n",
        "\n",
        "        df_null = df[df[passed_col].isnull()]\n",
        "        df_not_null = df[df[passed_col].notnull()]\n",
        "\n",
        "        X = df_not_null.drop(passed_col, axis=1)\n",
        "        y = df_not_null[passed_col]\n",
        "\n",
        "        other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "\n",
        "        for col in X.columns:\n",
        "            if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
        "                X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "        iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)\n",
        "\n",
        "        for col in other_missing_cols:\n",
        "            if X[col].isnull().sum() > 0:\n",
        "                col_with_missing_values = X[col].values.reshape(-1, 1)\n",
        "                imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
        "                X[col] = imputed_values[:, 0]\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        rf_regressor = RandomForestRegressor()\n",
        "\n",
        "        rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = rf_regressor.predict(X_test)\n",
        "\n",
        "        print(\"MAE =\", mean_absolute_error(y_test, y_pred), \"\\n\")\n",
        "        print(\"RMSE =\", mean_squared_error(y_test, y_pred, squared=False), \"\\n\")\n",
        "        print(\"R2 =\", r2_score(y_test, y_pred), \"\\n\")\n",
        "\n",
        "        X = df_null.drop(passed_col, axis=1)\n",
        "\n",
        "        for col in X.columns:\n",
        "            if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
        "                X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "        for col in other_missing_cols:\n",
        "            if X[col].isnull().sum() > 0:\n",
        "                col_with_missing_values = X[col].values.reshape(-1, 1)\n",
        "                imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
        "                X[col] = imputed_values[:, 0]\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        if len(df_null) > 0:\n",
        "            df_null[passed_col] = rf_regressor.predict(X)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        df_combined = pd.concat([df_not_null, df_null])\n",
        "\n",
        "        return df_combined[passed_col]\n",
        "\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # impute missing values using our functions\n",
        "    for col in missing_data_cols:\n",
        "        print(\"Missing Values\", col, \":\", str(round((df[col].isnull().sum() / len(df)) * 100, 2))+\"%\")\n",
        "        if col in categorical_cols:\n",
        "            df[col] = impute_categorical_missing_data(col)\n",
        "        elif col in numerical_cols:\n",
        "            df[col] = impute_continuous_missing_data(col)\n",
        "    return df"
      ],
      "metadata": {
        "id": "XKXqM9FUJMSt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "R66x2Rp8DMPY"
      },
      "outputs": [],
      "source": [
        "def encodeDf(imputeMethod):\n",
        "\n",
        "  train_df, test_df = read_data()\n",
        "  # Concatenate train and test DataFrames\n",
        "  train_df['ifTrain'] = 1\n",
        "  test_df['ifTrain'] = 0\n",
        "  df_concatenated = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "  df_concatenated = imputeMethod(df_concatenated)\n",
        "\n",
        "  # Define column categories\n",
        "  ordinal_cols = ['slope', 'thal']\n",
        "  nominal_cols = ['cp', 'restecg', 'sex']\n",
        "  bool_cols = ['exang', 'fbs']\n",
        "  numerical_cols = ['oldpeak', 'thalch', 'chol', 'trestbps', 'age']\n",
        "\n",
        "  # Initialize encoders and scaler\n",
        "  minmax_scaler = MinMaxScaler()\n",
        "  onehot_encoder = OneHotEncoder(drop='first', sparse=False)  # drop first to avoid dummy trap\n",
        "  ordinal_encoder = OrdinalEncoder()\n",
        "\n",
        "  # Scale numerical columns\n",
        "  df_concatenated[numerical_cols] = minmax_scaler.fit_transform(df_concatenated[numerical_cols])\n",
        "\n",
        "  # Encode ordinal columns\n",
        "  df_concatenated[ordinal_cols] = ordinal_encoder.fit_transform(df_concatenated[ordinal_cols])\n",
        "\n",
        "  # One-hot encode nominal columns and get a DataFrame with new column names\n",
        "  onehot_encoded = onehot_encoder.fit_transform(df_concatenated[nominal_cols])\n",
        "  df_nominal_encoded = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out())\n",
        "\n",
        "  # Concatenate the one-hot encoded nominal DataFrame with the original df\n",
        "  # Make sure to reset the index before concatenation to align the rows correctly\n",
        "  df_concatenated = df_concatenated.reset_index(drop=True)\n",
        "  df_nominal_encoded = df_nominal_encoded.reset_index(drop=True)\n",
        "  df_encoded = pd.concat([df_concatenated, df_nominal_encoded], axis=1)\n",
        "\n",
        "  # Now drop the original nominal columns as they have been one-hot encoded\n",
        "  df_encoded = df_encoded.drop(columns=nominal_cols)\n",
        "\n",
        "  # Ensure the 'id' column is dropped if it's not needed\n",
        "  df_encoded = df_encoded.drop(columns=['id'])\n",
        "  df_encoded = df_encoded.drop('dataset', axis=1)\n",
        "  df_encoded['fbs'] = df_encoded['fbs'].astype(float)\n",
        "  df_encoded['exang'] = df_encoded['exang'].astype(float)\n",
        "\n",
        "\n",
        "  # Split the encoded DataFrame back into train and test sets based on 'ifTrain' column\n",
        "  train_set = df_encoded[df_encoded['ifTrain'] == 1].drop(columns=['ifTrain'])\n",
        "  test_set = df_encoded[df_encoded['ifTrain'] == 0].drop(columns=['ifTrain'])\n",
        "\n",
        "  # Optionally, you can also split your train data into train and validation sets if needed\n",
        "  # X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "  y_train = train_set['num']\n",
        "  X_train = train_set.drop(columns = ['num'])\n",
        "  y_test = test_set['num']\n",
        "  X_test = test_set.drop(columns = ['num'])\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = encodeDf(imputeMethod = imputeML)"
      ],
      "metadata": {
        "id": "7CJsTwjGGPgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2364a190-a5aa-4158-a558-591101c69456"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values trestbps : 6.41%\n",
            "MAE = 15.096242774566475 \n",
            "\n",
            "RMSE = 20.989818162003893 \n",
            "\n",
            "R2 = -0.003806314903271879 \n",
            "\n",
            "Missing Values chol : 3.26%\n",
            "MAE = 43.64258426966292 \n",
            "\n",
            "RMSE = 64.61237512350961 \n",
            "\n",
            "R2 = 0.6489413238162391 \n",
            "\n",
            "Missing Values fbs : 9.78%\n",
            "The feature 'fbs' has been imputed with 83.73 accuracy\n",
            "\n",
            "Missing Values restecg : 0.22%\n",
            "The feature 'restecg' has been imputed with 63.59 accuracy\n",
            "\n",
            "Missing Values thalch : 5.98%\n",
            "MAE = 16.526416184971097 \n",
            "\n",
            "RMSE = 20.6979112765968 \n",
            "\n",
            "R2 = 0.3881620621652334 \n",
            "\n",
            "Missing Values exang : 5.98%\n",
            "The feature 'exang' has been imputed with 80.92 accuracy\n",
            "\n",
            "Missing Values oldpeak : 6.74%\n",
            "MAE = 0.5180290697674419 \n",
            "\n",
            "RMSE = 0.7707210946989537 \n",
            "\n",
            "R2 = 0.5048796729931088 \n",
            "\n",
            "Missing Values slope : 33.59%\n",
            "The feature 'slope' has been imputed with 75.61 accuracy\n",
            "\n",
            "Missing Values ca : 66.41%\n",
            "The feature 'ca' has been imputed with 58.06 accuracy\n",
            "\n",
            "Missing Values thal : 52.83%\n",
            "The feature 'thal' has been imputed with 59.77 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6UH3i56zKCL7",
        "outputId": "579f5771-4da7-4e21-8445-3703db974825"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          age  trestbps      chol  fbs    thalch  exang   oldpeak  slope   ca  \\\n",
              "860  0.612245     0.570  0.527363  0.0  0.563380    0.0  0.795455    0.0  3.0   \n",
              "861  0.285714     0.650  0.298507  0.0  0.633803    0.0  0.295455    2.0  0.0   \n",
              "862  0.591837     0.660  0.343284  0.0  0.760563    1.0  0.295455    2.0  0.0   \n",
              "863  0.510204     0.700  0.336650  1.0  0.669014    1.0  0.647727    0.0  0.0   \n",
              "864  0.469388     0.700  0.510779  0.0  0.577465    0.0  0.465909    2.0  1.0   \n",
              "865  0.551020     0.640  0.339967  0.0  0.492958    1.0  0.522727    1.0  1.0   \n",
              "866  0.714286     0.675  0.417910  0.0  0.788732    0.0  0.295455    2.0  0.0   \n",
              "867  0.673469     0.725  0.509121  0.0  0.605634    1.0  0.409091    1.0  0.0   \n",
              "868  0.571429     0.600  0.391376  0.0  0.830986    0.0  0.386364    2.0  0.0   \n",
              "869  0.591837     0.760  0.454395  0.0  0.197183    1.0  0.431818    1.0  1.0   \n",
              "870  0.489796     0.670  0.333333  0.0  0.690141    0.0  0.386364    2.0  1.0   \n",
              "871  0.448980     0.600  0.404643  0.0  0.718310    0.0  0.420455    2.0  0.0   \n",
              "872  0.285714     0.600  0.398010  1.0  0.943662    0.0  0.386364    0.0  0.0   \n",
              "873  0.857143     0.650  0.533997  0.0  0.345070    0.0  0.568182    1.0  3.0   \n",
              "874  0.265306     0.550  0.285240  0.0  0.690141    0.0  0.295455    2.0  0.0   \n",
              "875  0.469388     0.650  0.505804  0.0  0.577465    1.0  0.431818    1.0  0.0   \n",
              "876  0.346939     0.640  0.510779  0.0  0.774648    0.0  0.295455    2.0  0.0   \n",
              "877  0.224490     0.590  0.363184  0.0  0.563380    0.0  0.431818    1.0  0.0   \n",
              "878  0.530612     0.675  0.504146  1.0  0.774648    0.0  0.295455    2.0  0.0   \n",
              "879  0.632653     0.850  0.477612  0.0  0.697183    0.0  0.318182    1.0  0.0   \n",
              "880  0.469388     0.700  0.495854  0.0  0.795775    1.0  0.477273    2.0  0.0   \n",
              "881  0.530612     0.540  0.512438  0.0  0.676056    0.0  0.295455    2.0  0.0   \n",
              "882  0.591837     0.550  0.333333  0.0  0.464789    1.0  0.465909    1.0  0.0   \n",
              "883  0.469388     0.550  0.290216  0.0  0.443662    0.0  0.363636    2.0  0.0   \n",
              "884  0.877551     0.800  0.500829  0.0  0.718310    0.0  0.340909    2.0  2.0   \n",
              "885  0.612245     0.650  0.326700  0.0  0.500000    0.0  0.363636    1.0  0.0   \n",
              "886  0.673469     0.740  0.336650  0.0  0.711268    0.0  0.295455    2.0  1.0   \n",
              "887  0.142857     0.690  0.303483  0.0  0.859155    0.0  0.454545    2.0  0.0   \n",
              "888  0.367347     0.525  0.338308  0.0  0.788732    0.0  0.295455    2.0  0.0   \n",
              "889  0.285714     0.600  0.489221  0.0  0.718310    0.0  0.295455    2.0  0.0   \n",
              "890  0.530612     0.700  0.396352  0.0  0.704225    0.0  0.431818    2.0  0.0   \n",
              "891  0.428571     0.650  0.446103  0.0  0.725352    0.0  0.295455    2.0  0.0   \n",
              "892  0.632653     0.675  0.388060  0.0  0.711268    0.0  0.352273    1.0  0.0   \n",
              "893  0.653061     0.650  0.341625  0.0  0.507042    1.0  0.568182    1.0  2.0   \n",
              "894  0.612245     0.560  0.381426  0.0  0.739437    0.0  0.579545    1.0  1.0   \n",
              "895  0.591837     0.600  0.587065  0.0  0.725352    1.0  0.363636    2.0  0.0   \n",
              "896  0.693878     0.650  0.436153  0.0  0.260563    0.0  0.431818    1.0  1.0   \n",
              "897  0.346939     0.690  0.391376  0.0  0.647887    1.0  0.318182    1.0  0.0   \n",
              "898  0.489796     0.590  0.308458  0.0  0.915493    0.0  0.295455    1.0  0.0   \n",
              "899  0.326531     0.540  0.233831  0.0  0.809859    0.0  0.363636    1.0  0.0   \n",
              "900  0.755102     0.800  0.597015  0.0  0.640845    0.0  0.386364    2.0  0.0   \n",
              "901  0.224490     0.700  0.532338  0.0  0.859155    0.0  0.295455    2.0  0.0   \n",
              "902  0.755102     0.675  0.421227  0.0  0.471831    0.0  0.613636    1.0  1.0   \n",
              "903  0.653061     0.625  0.427861  0.0  0.570423    1.0  0.613636    1.0  1.0   \n",
              "904  0.530612     0.600  0.427861  0.0  0.612676    0.0  0.340909    1.0  0.0   \n",
              "905  0.448980     0.550  0.421227  0.0  0.697183    0.0  0.295455    2.0  0.0   \n",
              "906  0.775510     0.890  0.378109  1.0  0.739437    1.0  0.409091    1.0  2.0   \n",
              "907  0.714286     0.700  0.310116  0.0  0.591549    1.0  0.750000    2.0  2.0   \n",
              "908  0.224490     0.470  0.330017  0.0  0.838028    0.0  0.295455    2.0  0.0   \n",
              "909  0.408163     0.620  0.454395  0.0  0.746479    0.0  0.352273    1.0  0.0   \n",
              "910  0.387755     0.540  0.402985  0.0  0.647887    0.0  0.295455    2.0  0.0   \n",
              "911  0.530612     0.960  0.469320  0.0  0.950704    0.0  0.295455    2.0  1.0   \n",
              "912  0.489796     0.600  0.538972  0.0  0.788732    0.0  0.318182    2.0  0.0   \n",
              "913  0.612245     0.730  0.361526  0.0  0.316901    0.0  0.522727    1.0  1.0   \n",
              "914  0.387755     0.650  0.419569  0.0  0.838028    0.0  0.295455    2.0  0.0   \n",
              "915  0.755102     0.550  0.411277  0.0  0.690141    0.0  0.363636    2.0  2.0   \n",
              "916  0.387755     0.550  0.456053  0.0  0.408451    1.0  0.409091    1.0  1.0   \n",
              "917  0.448980     0.600  0.363184  0.0  0.690141    0.0  0.477273    1.0  0.0   \n",
              "918  0.265306     0.650  0.354892  0.0  0.760563    0.0  0.522727    1.0  0.0   \n",
              "919  0.469388     0.625  0.353234  0.0  0.457746    1.0  0.454545    2.0  1.0   \n",
              "\n",
              "     thal  cp_atypical angina  cp_non-anginal  cp_typical angina  \\\n",
              "860   0.0                 0.0             0.0                0.0   \n",
              "861   1.0                 0.0             1.0                0.0   \n",
              "862   2.0                 0.0             0.0                0.0   \n",
              "863   2.0                 0.0             0.0                0.0   \n",
              "864   1.0                 0.0             1.0                0.0   \n",
              "865   2.0                 0.0             0.0                0.0   \n",
              "866   1.0                 0.0             1.0                0.0   \n",
              "867   2.0                 0.0             0.0                0.0   \n",
              "868   1.0                 1.0             0.0                0.0   \n",
              "869   2.0                 0.0             0.0                0.0   \n",
              "870   1.0                 1.0             0.0                0.0   \n",
              "871   1.0                 1.0             0.0                0.0   \n",
              "872   2.0                 0.0             1.0                0.0   \n",
              "873   1.0                 0.0             0.0                0.0   \n",
              "874   2.0                 0.0             0.0                0.0   \n",
              "875   2.0                 0.0             0.0                0.0   \n",
              "876   1.0                 1.0             0.0                0.0   \n",
              "877   2.0                 0.0             0.0                0.0   \n",
              "878   1.0                 0.0             1.0                0.0   \n",
              "879   2.0                 0.0             0.0                1.0   \n",
              "880   2.0                 0.0             0.0                0.0   \n",
              "881   2.0                 1.0             0.0                0.0   \n",
              "882   0.0                 0.0             0.0                0.0   \n",
              "883   1.0                 0.0             1.0                0.0   \n",
              "884   1.0                 1.0             0.0                0.0   \n",
              "885   1.0                 0.0             0.0                0.0   \n",
              "886   2.0                 0.0             0.0                0.0   \n",
              "887   1.0                 0.0             0.0                0.0   \n",
              "888   1.0                 1.0             0.0                0.0   \n",
              "889   1.0                 1.0             0.0                0.0   \n",
              "890   1.0                 0.0             0.0                0.0   \n",
              "891   1.0                 0.0             0.0                0.0   \n",
              "892   2.0                 0.0             0.0                0.0   \n",
              "893   2.0                 0.0             0.0                0.0   \n",
              "894   2.0                 0.0             1.0                0.0   \n",
              "895   1.0                 0.0             0.0                0.0   \n",
              "896   2.0                 0.0             1.0                0.0   \n",
              "897   1.0                 0.0             0.0                0.0   \n",
              "898   0.0                 0.0             0.0                1.0   \n",
              "899   1.0                 0.0             1.0                0.0   \n",
              "900   1.0                 0.0             1.0                0.0   \n",
              "901   1.0                 0.0             1.0                0.0   \n",
              "902   2.0                 0.0             0.0                0.0   \n",
              "903   2.0                 0.0             0.0                0.0   \n",
              "904   2.0                 0.0             1.0                0.0   \n",
              "905   1.0                 0.0             0.0                0.0   \n",
              "906   2.0                 0.0             0.0                0.0   \n",
              "907   2.0                 0.0             0.0                0.0   \n",
              "908   1.0                 0.0             1.0                0.0   \n",
              "909   2.0                 0.0             0.0                0.0   \n",
              "910   1.0                 0.0             1.0                0.0   \n",
              "911   2.0                 1.0             0.0                0.0   \n",
              "912   1.0                 1.0             0.0                0.0   \n",
              "913   2.0                 0.0             0.0                0.0   \n",
              "914   1.0                 0.0             1.0                0.0   \n",
              "915   0.0                 0.0             0.0                0.0   \n",
              "916   1.0                 0.0             0.0                0.0   \n",
              "917   1.0                 0.0             1.0                0.0   \n",
              "918   1.0                 0.0             1.0                0.0   \n",
              "919   1.0                 0.0             0.0                1.0   \n",
              "\n",
              "     restecg_normal  restecg_st-t abnormality  sex_Male  \n",
              "860             0.0                       1.0       1.0  \n",
              "861             1.0                       0.0       1.0  \n",
              "862             1.0                       0.0       1.0  \n",
              "863             0.0                       0.0       1.0  \n",
              "864             0.0                       0.0       0.0  \n",
              "865             0.0                       1.0       0.0  \n",
              "866             0.0                       0.0       0.0  \n",
              "867             0.0                       0.0       0.0  \n",
              "868             1.0                       0.0       1.0  \n",
              "869             1.0                       0.0       1.0  \n",
              "870             1.0                       0.0       1.0  \n",
              "871             1.0                       0.0       0.0  \n",
              "872             1.0                       0.0       1.0  \n",
              "873             0.0                       0.0       1.0  \n",
              "874             0.0                       0.0       1.0  \n",
              "875             1.0                       0.0       0.0  \n",
              "876             0.0                       0.0       1.0  \n",
              "877             1.0                       0.0       1.0  \n",
              "878             1.0                       0.0       0.0  \n",
              "879             0.0                       0.0       1.0  \n",
              "880             1.0                       0.0       1.0  \n",
              "881             1.0                       0.0       1.0  \n",
              "882             1.0                       0.0       1.0  \n",
              "883             1.0                       0.0       1.0  \n",
              "884             1.0                       0.0       0.0  \n",
              "885             1.0                       0.0       0.0  \n",
              "886             1.0                       0.0       1.0  \n",
              "887             1.0                       0.0       0.0  \n",
              "888             1.0                       0.0       0.0  \n",
              "889             1.0                       0.0       1.0  \n",
              "890             1.0                       0.0       1.0  \n",
              "891             1.0                       0.0       0.0  \n",
              "892             1.0                       0.0       1.0  \n",
              "893             0.0                       0.0       1.0  \n",
              "894             0.0                       0.0       1.0  \n",
              "895             1.0                       0.0       0.0  \n",
              "896             1.0                       0.0       0.0  \n",
              "897             0.0                       0.0       0.0  \n",
              "898             0.0                       0.0       1.0  \n",
              "899             1.0                       0.0       0.0  \n",
              "900             0.0                       0.0       0.0  \n",
              "901             0.0                       0.0       1.0  \n",
              "902             0.0                       0.0       1.0  \n",
              "903             0.0                       0.0       1.0  \n",
              "904             0.0                       0.0       1.0  \n",
              "905             0.0                       0.0       0.0  \n",
              "906             1.0                       0.0       0.0  \n",
              "907             0.0                       0.0       1.0  \n",
              "908             1.0                       0.0       0.0  \n",
              "909             0.0                       0.0       1.0  \n",
              "910             1.0                       0.0       1.0  \n",
              "911             0.0                       0.0       1.0  \n",
              "912             1.0                       0.0       1.0  \n",
              "913             1.0                       0.0       1.0  \n",
              "914             1.0                       0.0       1.0  \n",
              "915             0.0                       0.0       1.0  \n",
              "916             0.0                       0.0       1.0  \n",
              "917             1.0                       0.0       0.0  \n",
              "918             0.0                       0.0       1.0  \n",
              "919             0.0                       0.0       1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b83fb62-47f2-472a-9114-c53668a754b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>thalch</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>cp_atypical angina</th>\n",
              "      <th>cp_non-anginal</th>\n",
              "      <th>cp_typical angina</th>\n",
              "      <th>restecg_normal</th>\n",
              "      <th>restecg_st-t abnormality</th>\n",
              "      <th>sex_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.527363</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.563380</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.795455</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.633803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.660</td>\n",
              "      <td>0.343284</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.760563</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>0.510204</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.336650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.669014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.647727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>0.469388</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.510779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.577465</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.465909</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.339967</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.492958</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.417910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>0.673469</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.509121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.605634</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.391376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.830986</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386364</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.454395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.197183</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870</th>\n",
              "      <td>0.489796</td>\n",
              "      <td>0.670</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386364</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>0.448980</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.404643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.718310</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.420455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.398010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.943662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.533997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.345070</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.568182</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>0.265306</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.285240</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>0.469388</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.505804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.577465</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>0.346939</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.510779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.774648</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>0.224490</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.363184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.563380</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.504146</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.774648</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.850</td>\n",
              "      <td>0.477612</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.697183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>0.469388</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.495854</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.795775</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.477273</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.512438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.676056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.464789</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.465909</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>0.469388</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.290216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.443662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.500829</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.718310</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.340909</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.326700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0.673469</td>\n",
              "      <td>0.740</td>\n",
              "      <td>0.336650</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.711268</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.690</td>\n",
              "      <td>0.303483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.859155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0.367347</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.338308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.489221</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.718310</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.396352</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.704225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.446103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.725352</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.388060</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.711268</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352273</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>0.653061</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.341625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.568182</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894</th>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.381426</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739437</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.579545</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.587065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.725352</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>0.693878</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.436153</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260563</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>0.346939</td>\n",
              "      <td>0.690</td>\n",
              "      <td>0.391376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.647887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>0.489796</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.308458</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915493</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>0.326531</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.233831</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.809859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>900</th>\n",
              "      <td>0.755102</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.597015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.640845</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386364</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>901</th>\n",
              "      <td>0.224490</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.532338</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.859155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>902</th>\n",
              "      <td>0.755102</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.421227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.471831</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.613636</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>0.653061</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.427861</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.570423</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.613636</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>904</th>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.427861</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.612676</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.340909</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>0.448980</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.421227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.697183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.378109</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.739437</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.310116</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.591549</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>0.224490</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.330017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.838028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>0.408163</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.454395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.746479</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352273</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>910</th>\n",
              "      <td>0.387755</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.402985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.647887</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>911</th>\n",
              "      <td>0.530612</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.469320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950704</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>0.489796</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.538972</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.730</td>\n",
              "      <td>0.361526</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.316901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>914</th>\n",
              "      <td>0.387755</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.419569</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.838028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>0.755102</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.411277</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>0.387755</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.456053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408451</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>0.448980</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.363184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.690141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477273</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>0.265306</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.354892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>0.469388</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.353234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.457746</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b83fb62-47f2-472a-9114-c53668a754b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b83fb62-47f2-472a-9114-c53668a754b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b83fb62-47f2-472a-9114-c53668a754b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b79f4cc8-29cd-4d0e-a09f-d4f46d3ee907\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b79f4cc8-29cd-4d0e-a09f-d4f46d3ee907')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b79f4cc8-29cd-4d0e-a09f-d4f46d3ee907 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test",
              "summary": "{\n  \"name\": \"X_test\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16792994765499056,\n        \"min\": 0.1428571428571428,\n        \"max\": 0.8775510204081631,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          0.4897959183673468,\n          0.7755102040816326,\n          0.5714285714285714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09022554913944345,\n        \"min\": 0.47000000000000003,\n        \"max\": 0.96,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.76,\n          0.6900000000000001,\n          0.5700000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08244748546980919,\n        \"min\": 0.2338308457711443,\n        \"max\": 0.5970149253731344,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          0.49585406301824214,\n          0.31011608623548925,\n          0.4195688225538972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2515488742932317,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16133381351521298,\n        \"min\": 0.19718309859154937,\n        \"max\": 0.9507042253521126,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.5070422535211268,\n          0.34507042253521125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4459484908564836,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1187318978370649,\n        \"min\": 0.29545454545454547,\n        \"max\": 0.7954545454545454,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.7954545454545454,\n          0.4090909090909091\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5963637459756623,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7917298517752694,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6057632809459259,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp_atypical angina\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3758230140014145,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp_non-anginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4544196025054849,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp_typical angina\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21978417765108274,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg_normal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5016920522135438,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg_st-t abnormality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18102033471939247,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex_Male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48099473199130766,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# \n",
        "model_params = {\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'solver': ['liblinear', 'lbfgs','sag','saga']\n",
        "        }\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'params': {\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    'Bayesian Classifier': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {\n",
        "            'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# \n",
        "best_models = {}\n",
        "results = []\n",
        "\n",
        "# \n",
        "for model_name, mp in model_params.items():\n",
        "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_models[model_name] = clf.best_estimator_\n",
        "    y_pred = clf.best_estimator_.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    results.append({\n",
        "        'model': model_name,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_,\n",
        "        'test_accuracy': accuracy,\n",
        "        'classification_report': report\n",
        "    })\n",
        "\n",
        "# \n",
        "for result in results:\n",
        "    print(f\"Model: {result['model']}\")\n",
        "    print(\"Best Score (CV):\", result['best_score'])\n",
        "    print(\"Best Parameters:\", result['best_params'])\n",
        "    print(\"Test Accuracy:\", result['test_accuracy'])\n",
        "    print(\"Classification Report:\\n\", result['classification_report'])\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# \n",
        "best_model = max(results, key=lambda x: x['test_accuracy'])\n",
        "print(f\"Overall Best Model: {best_model['model']} with Test Accuracy: {best_model['test_accuracy']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaQ13bt0bRb_",
        "outputId": "f80c7dc0-c0ef-4fa3-cad6-545bed9d4d89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Best Score (CV): 0.8162790697674419\n",
            "Best Parameters: {'C': 0.1, 'solver': 'liblinear'}\n",
            "Test Accuracy: 0.8333333333333334\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.83      0.85        35\n",
            "           1       0.78      0.84      0.81        25\n",
            "\n",
            "    accuracy                           0.83        60\n",
            "   macro avg       0.83      0.83      0.83        60\n",
            "weighted avg       0.84      0.83      0.83        60\n",
            "\n",
            "------------------------------\n",
            "Model: Decision Tree\n",
            "Best Score (CV): 0.7325581395348838\n",
            "Best Parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
            "Test Accuracy: 0.8166666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85        35\n",
            "           1       0.79      0.76      0.78        25\n",
            "\n",
            "    accuracy                           0.82        60\n",
            "   macro avg       0.81      0.81      0.81        60\n",
            "weighted avg       0.82      0.82      0.82        60\n",
            "\n",
            "------------------------------\n",
            "Model: Bayesian Classifier\n",
            "Best Score (CV): 0.8023255813953488\n",
            "Best Parameters: {'var_smoothing': 1e-09}\n",
            "Test Accuracy: 0.8166666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86        35\n",
            "           1       0.89      0.64      0.74        25\n",
            "\n",
            "    accuracy                           0.82        60\n",
            "   macro avg       0.84      0.79      0.80        60\n",
            "weighted avg       0.83      0.82      0.81        60\n",
            "\n",
            "------------------------------\n",
            "Overall Best Model: Logistic Regression with Test Accuracy: 0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = encodeDf(imputeMethod = imputeMean)"
      ],
      "metadata": {
        "id": "kmkThBlTP48h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train.isnull().sum()/ len(X_train)* 100).sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbob-BykcJrs",
        "outputId": "fbe55c60-d6ee-4ace-e817-884ee74fd6c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                         0.0\n",
              "trestbps                    0.0\n",
              "chol                        0.0\n",
              "fbs                         0.0\n",
              "thalch                      0.0\n",
              "exang                       0.0\n",
              "oldpeak                     0.0\n",
              "slope                       0.0\n",
              "ca                          0.0\n",
              "thal                        0.0\n",
              "cp_atypical angina          0.0\n",
              "cp_non-anginal              0.0\n",
              "cp_typical angina           0.0\n",
              "restecg_normal              0.0\n",
              "restecg_st-t abnormality    0.0\n",
              "sex_Male                    0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# \n",
        "model_params = {\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'solver': ['liblinear', 'lbfgs','sag','saga']\n",
        "        }\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'params': {\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    'Bayesian Classifier': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {\n",
        "            'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# \n",
        "best_models = {}\n",
        "results = []\n",
        "\n",
        "# \n",
        "for model_name, mp in model_params.items():\n",
        "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_models[model_name] = clf.best_estimator_\n",
        "    y_pred = clf.best_estimator_.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    results.append({\n",
        "        'model': model_name,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_,\n",
        "        'test_accuracy': accuracy,\n",
        "        'classification_report': report\n",
        "    })\n",
        "\n",
        "# \n",
        "for result in results:\n",
        "    print(f\"Model: {result['model']}\")\n",
        "    print(\"Best Score (CV):\", result['best_score'])\n",
        "    print(\"Best Parameters:\", result['best_params'])\n",
        "    print(\"Test Accuracy:\", result['test_accuracy'])\n",
        "    print(\"Classification Report:\\n\", result['classification_report'])\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# \n",
        "best_model = max(results, key=lambda x: x['test_accuracy'])\n",
        "print(f\"Overall Best Model: {best_model['model']} with Test Accuracy: {best_model['test_accuracy']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZtFCJYabnNt",
        "outputId": "0ec55e97-0f0a-4809-95a5-6768674bb754"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Best Score (CV): 0.7848837209302325\n",
            "Best Parameters: {'C': 0.1, 'solver': 'liblinear'}\n",
            "Test Accuracy: 0.8166666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85        35\n",
            "           1       0.79      0.76      0.78        25\n",
            "\n",
            "    accuracy                           0.82        60\n",
            "   macro avg       0.81      0.81      0.81        60\n",
            "weighted avg       0.82      0.82      0.82        60\n",
            "\n",
            "------------------------------\n",
            "Model: Decision Tree\n",
            "Best Score (CV): 0.6709302325581394\n",
            "Best Parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
            "Test Accuracy: 0.7\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.74      0.74        35\n",
            "           1       0.64      0.64      0.64        25\n",
            "\n",
            "    accuracy                           0.70        60\n",
            "   macro avg       0.69      0.69      0.69        60\n",
            "weighted avg       0.70      0.70      0.70        60\n",
            "\n",
            "------------------------------\n",
            "Model: Bayesian Classifier\n",
            "Best Score (CV): 0.7639534883720931\n",
            "Best Parameters: {'var_smoothing': 1e-09}\n",
            "Test Accuracy: 0.8833333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90        35\n",
            "           1       0.88      0.84      0.86        25\n",
            "\n",
            "    accuracy                           0.88        60\n",
            "   macro avg       0.88      0.88      0.88        60\n",
            "weighted avg       0.88      0.88      0.88        60\n",
            "\n",
            "------------------------------\n",
            "Overall Best Model: Bayesian Classifier with Test Accuracy: 0.8833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = encodeDf(imputeMethod = drop)"
      ],
      "metadata": {
        "id": "D34Q09C_cgRh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# \n",
        "model_params = {\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'solver': ['liblinear', 'lbfgs','sag','saga']\n",
        "        }\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'params': {\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    'Bayesian Classifier': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {\n",
        "            'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# \n",
        "best_models = {}\n",
        "results = []\n",
        "\n",
        "# \n",
        "for model_name, mp in model_params.items():\n",
        "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_models[model_name] = clf.best_estimator_\n",
        "    y_pred = clf.best_estimator_.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    results.append({\n",
        "        'model': model_name,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_,\n",
        "        'test_accuracy': accuracy,\n",
        "        'classification_report': report\n",
        "    })\n",
        "\n",
        "# \n",
        "for result in results:\n",
        "    print(f\"Model: {result['model']}\")\n",
        "    print(\"Best Score (CV):\", result['best_score'])\n",
        "    print(\"Best Parameters:\", result['best_params'])\n",
        "    print(\"Test Accuracy:\", result['test_accuracy'])\n",
        "    print(\"Classification Report:\\n\", result['classification_report'])\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# \n",
        "best_model = max(results, key=lambda x: x['test_accuracy'])\n",
        "print(f\"Overall Best Model: {best_model['model']} with Test Accuracy: {best_model['test_accuracy']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9MQls4GclJN",
        "outputId": "ba7b30ca-bbad-41bf-b7de-1512c921013f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Best Score (CV): 0.8324468085106383\n",
            "Best Parameters: {'C': 0.1, 'solver': 'lbfgs'}\n",
            "Test Accuracy: 0.8833333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90        35\n",
            "           1       0.91      0.80      0.85        25\n",
            "\n",
            "    accuracy                           0.88        60\n",
            "   macro avg       0.89      0.87      0.88        60\n",
            "weighted avg       0.89      0.88      0.88        60\n",
            "\n",
            "------------------------------\n",
            "Model: Decision Tree\n",
            "Best Score (CV): 0.7155141843971631\n",
            "Best Parameters: {'max_depth': 20, 'min_samples_split': 10}\n",
            "Test Accuracy: 0.8\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.77      0.82        35\n",
            "           1       0.72      0.84      0.78        25\n",
            "\n",
            "    accuracy                           0.80        60\n",
            "   macro avg       0.80      0.81      0.80        60\n",
            "weighted avg       0.81      0.80      0.80        60\n",
            "\n",
            "------------------------------\n",
            "Model: Bayesian Classifier\n",
            "Best Score (CV): 0.7486702127659575\n",
            "Best Parameters: {'var_smoothing': 1e-07}\n",
            "Test Accuracy: 0.8833333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90        35\n",
            "           1       0.88      0.84      0.86        25\n",
            "\n",
            "    accuracy                           0.88        60\n",
            "   macro avg       0.88      0.88      0.88        60\n",
            "weighted avg       0.88      0.88      0.88        60\n",
            "\n",
            "------------------------------\n",
            "Overall Best Model: Logistic Regression with Test Accuracy: 0.8833333333333333\n"
          ]
        }
      ]
    }
  ]
}